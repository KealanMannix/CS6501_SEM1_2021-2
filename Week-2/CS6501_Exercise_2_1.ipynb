{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS6501_Exercise_2_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcVMEKIOSIa0"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
        "</div> \n",
        "\n",
        "#**Artificial Intelligence - MSc**\n",
        "CS6501 - MACHINE LEARNING APPLICATIONS \n",
        "\n",
        "###Instructor: Enrique Naredo\n",
        "###CS6501_Exercise_2.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuZ0F5C9qUmr"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4759neSP_Kh"
      },
      "source": [
        "# import libraries\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from pandas import DataFrame\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLp5xCeOqMEV"
      },
      "source": [
        "## Synthetic Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTSNAvMfRYFn"
      },
      "source": [
        "Generate isotropic Gaussian blobs using \"[make_blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmQAB80HQxfC"
      },
      "source": [
        "## randomly generate a 2d, 2 classes dataset\n",
        "# using: n_samples=200\n",
        "\n",
        "X4, y4 = \n",
        "# create a data frame\n",
        "df = DataFrame(dict(x=X1[:,0], y=X1[:,1], label=y1))\n",
        "\n",
        "# use: 'green', 'cyan'\n",
        "colors = \n",
        "\n",
        "# figure\n",
        "fig, ax = plt.subplots()\n",
        "grouped = df.groupby('label')\n",
        "\n",
        "# scatter plot\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFLeyfH0UeW2"
      },
      "source": [
        "# show first 7 rows\n",
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrM6v2A6pMfb"
      },
      "source": [
        "# count the data elements for each class\n",
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZZS9l69qwVJ"
      },
      "source": [
        "## Logistic Regresion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIgx7MOprsnT"
      },
      "source": [
        "* [Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. \n",
        "* In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression). \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsRi3LDyNyKI"
      },
      "source": [
        "# Logistic Regression model\n",
        "LR_model = LogisticRegression()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyjd46yftFug"
      },
      "source": [
        "# change the vars names to correctly run this cell\n",
        "LR_model.fit(X1, y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhoTcXVzqOHl"
      },
      "source": [
        "Decision boundary from [Wikipedia](https://en.wikipedia.org/wiki/Decision_boundary): \n",
        "\n",
        "* A decision boundary is the region of a problem space in \n",
        "which the output label of a classifier is ambiguous.\n",
        "\n",
        "* If the decision surface is a hyperplane, then the classification problem is linear, and the classes are linearly separable.\n",
        "\n",
        "* In a statistical-classification problem with two classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two sets, one for each class.\n",
        "\n",
        "* You can find a related information to this topic in this [publication](https://towardsdatascience.com/classification-problems-and-exploring-decision-boundaries-3317e03afcdb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jMzZwuqgyYv"
      },
      "source": [
        "# Plotting the decision boundary \n",
        "# change the vars names to correctly run this cell\n",
        "plot_decision_regions(X1, y1, clf=LR_model, legend=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDhJEg0LtsOk"
      },
      "source": [
        "# Plotting the decision boundary \n",
        "\n",
        "plot_decision_regions(X1, y1, clf=LR_model, legend=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QoKXFJtt5vF"
      },
      "source": [
        "# vary the value of pos from 1 to 10 (1,2,3,4,5,6,7,8,9,10)\n",
        "# and report your findings in the next cell\n",
        "pos = 1\n",
        "plot_decision_regions(X1, y1, clf=LR_model, legend=pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mCJAPNltzai"
      },
      "source": [
        "Here your report: \n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Ns97SgxHRP"
      },
      "source": [
        "## New Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTvTkAdzyQge"
      },
      "source": [
        "# new data instances, use 50 samples\n",
        "# and add the missing part of the code\n",
        "X_new, _ = make_blobs(, centers=2, n_features=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34ZOLzB_rFrK"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn2NQt61O7nA"
      },
      "source": [
        "# make predictions (assign class labels)\n",
        "# add the missing code in this cell\n",
        "\n",
        "\n",
        "y_pred = LR_model.predict()\n",
        "\n",
        "# show the inputs and predicted outputs\n",
        "for i in range(len()):\n",
        "  print(\"X{0} = {1}, Class Predicted = {2}\".format(i, [i], y_pred[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej4fLLOa2tth"
      },
      "source": [
        "# create a data frame\n",
        "# add the missing code in this cell\n",
        "\n",
        "df_new = DataFrame(dict(X_new[:,0], X_new[:,1], label=y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbEc5UPp0mmH"
      },
      "source": [
        "# show 7 rows \n",
        "df_new.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqyLkxR4xYLP"
      },
      "source": [
        "# use: 'red', 'blue'\n",
        "colors = {}\n",
        "\n",
        "# figure\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# new data\n",
        "grouped = df_new.groupby('label')\n",
        "\n",
        "# scatter plot\n",
        "# solve the issues you find with vars name\n",
        "for key2, group2 in grouped2:\n",
        "    group2.plot(ax=ax2, kind='scatter', x='x', y='y', label=key2, color=colors2[key2])\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUfxHcbG3r4p"
      },
      "source": [
        "# Plotting the new decision boundary \n",
        "# from the LogisticRegression model\n",
        "plot_decision_regions(X_new, y_pred, clf=LR_model, legend=2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
